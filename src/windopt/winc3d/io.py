"""
Read, write, and parse files for WInc3D.
"""

from pathlib import Path

import numpy as np
import pandas as pd

def read_adm_file(adm_file: Path):
    """
    Read a .adm file (really just a CSV).
    """
    return pd.read_csv(
            adm_file, sep=', ', engine='python'
            )

def tail(filename, n=10):
    with open(filename, 'rb') as f:
        # Go to end of file
        f.seek(0, 2)
        # Get file size
        size = f.tell()
        
        lines = []
        position = size
        
        # Read backwards until we have n lines
        while len(lines) < n and position > 0:
            # Move back one byte
            position -= 1
            f.seek(position)
            
            # Read one byte
            char = f.read(1)
            
            # If we hit a newline, store the line
            if char == b'\n':
                line = f.readline()
                lines.append(line.decode())
                
        # Reverse the lines since we read backwards
        return lines[::-1]

def is_job_completed_successfully(log_file: Path) -> bool:
    """
    Get the status of the job from the log file.
    """
    tail_lines = tail(log_file, 10)

    # on successful completion, the winc3d routine outputs the string "time per
    # time_step:" we can check for this pattern to determine if the job is
    # complete
    success_pattern = "time per time_step:"

    # TODO: this is a hack, but it works for now
    if success_pattern in ''.join(tail_lines):
        return True
    else:
        return False

def cleanup_viz_files(job_dir: Path):
    """
    Clean up large visualization files generated by WInc3D.
    """
    # remove all ux, uy, uz, pp, vort, and gammadisc files from job_dir/out
    subdir = Path(job_dir) / "out"
    patterns = ["ux*", "uy*", "uz*", "pp*", "vort*", "gammadisc*"]

    for pattern in patterns:
        for f in subdir.glob(pattern):
            f.unlink()

def turbine_results(job_dir: Path) -> pd.DataFrame:
    """
    Get the power history of each turbine from the job output.
    """
    # read *.adm files from the job_dir/out subdirectory
    n_files = len(list(job_dir.glob("out/discs_time[0-9]*.adm")))
    # parse each file and stack the results
    data = []
    for i in range(1, n_files + 1):
        adm_file = job_dir / f'out/discs_time{i}.adm'
        adm_info = read_adm_file(adm_file)
        adm_info['filenumber'] = i
        data.append(adm_info)
    return pd.concat(data).reset_index(names='turbine')

def read_turbine_information(job_dir: Path) -> pd.DataFrame:
    """
    Get the information of the turbines from the job output.
    """
    turbines_ad_file = job_dir / 'turbines.ad'
    if not turbines_ad_file.exists():
        raise ValueError(
            "Cannot find turbine locations! No turbines.ad "
            "found in job directory."
            )

    # the format is 7 space-separated floats, representing:
    # x y z normal_x normal_y normal_z rotor_diameter
    # for (x, y, z) the location of the turbine hub, and
    # (normal_x, normal_y, normal_z) the components of normal vector to the
    # turbine disk.
    turbines_df = pd.read_csv(turbines_ad_file, sep=' ', engine='python', header=None)
    turbines_df.columns = ['x', 'y', 'z', 'nx', 'ny', 'nz', 'D']
    return turbines_df

def read_turbine_locations(job_dir: Path) -> np.ndarray:
    """
    Get the (x, z) coordinates of the turbines from the job output.
    """
    return read_turbine_information(job_dir)[['x', 'z']].values
